---
title: "Multi-Wavelength Bioassay Analysis Report"
author: "Kristof Moeller (IAEA, Monaco) and Arnold Molina Porras (Universidad de Costa Rica)"
output:
  html_document:
    df_print: paged
    self_contained: true
    toc: true
    toc_float: true
  pdf_document:
    toc: true
  word_document:
    toc: true
params:
  output_dir: NULL
  wavelengths: NULL
  lang: "en"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(dplyr)
library(knitr)
library(kableExtra)
library(purrr)
library(ggplot2)
library(jsonlite)

output_dir <- normalizePath(params$output_dir, winslash = "/", mustWork = TRUE)

wavelengths <- params$wavelengths
if (is.null(wavelengths) || length(wavelengths) == 0) {
  stop("No wavelengths specified in parameters")
}

lang <- params$lang %||% "en"
`%||%` <- function(x, y) if (is.null(x)) y else x

script_dir <- tryCatch({
  rmd_path <- knitr::current_input()
  if (!is.null(rmd_path) && rmd_path != "" && rmd_path != ".") {
    d <- normalizePath(dirname(rmd_path), winslash = "/", mustWork = FALSE)
    if (d != "" && d != ".") d else normalizePath(".", winslash = "/")
  } else {
    normalizePath(".", winslash = "/")
  }
}, error = function(e) normalizePath(".", winslash = "/"))

# Source i18n translations (search multiple locations)
i18n_found <- FALSE
i18n_candidates <- unique(c(
  file.path(script_dir, "i18n.R"),
  file.path(dirname(script_dir), "i18n.R"),
  file.path(script_dir, "..", "i18n.R"),
  "../i18n.R",
  "i18n.R",
  file.path(dirname(output_dir), "i18n.R"),
  file.path(output_dir, "..", "i18n.R"),
  file.path(getwd(), "i18n.R"),
  file.path(getwd(), "..", "i18n.R")
))
for (i18n_candidate in i18n_candidates) {
  i18n_candidate <- tryCatch(normalizePath(i18n_candidate, winslash = "/", mustWork = FALSE), error = function(e) i18n_candidate)
  if (file.exists(i18n_candidate)) {
    source(i18n_candidate)
    i18n_found <- TRUE
    message("i18n.R loaded from: ", i18n_candidate)
    break
  }
}
if (!i18n_found) {
  message("WARNING: i18n.R not found. Searched: ", paste(i18n_candidates, collapse = ", "))
  tr <- function(key, lang = "en", ...) paste0("[", key, "]")
}

write_json_safe <- function(x, file) {
  dir.create(dirname(file), recursive = TRUE, showWarnings = FALSE)
  jsonlite::write_json(x, path = file, pretty = TRUE, auto_unbox = TRUE, null = "null")
}

# Load analysis settings
analysis_config <- tryCatch({
  cfg_file <- file.path(output_dir, "analysis_config.json")
  if (file.exists(cfg_file)) jsonlite::fromJSON(cfg_file)
  else list()
}, error = function(e) list())

preprocess_template_chunks <- function(template_path, label_prefix, temp_dir = tempdir()) {
  template_lines <- readLines(template_path, warn = FALSE)
  chunk_pattern <- "^```\\{r\\s+([^,}]+)"
  processed_lines <- sapply(template_lines, function(line) {
    if (grepl(chunk_pattern, line)) {
      chunk_match <- regmatches(line, regexpr(chunk_pattern, line, perl = TRUE))
      if (length(chunk_match) > 0) {
        chunk_name <- sub("^```\\{r\\s+", "", chunk_match)
        new_chunk_name <- paste0(label_prefix, "-", chunk_name)
        line <- sub(paste0("(```\\{r\\s+)", chunk_name),
                    paste0("\\1", new_chunk_name), line)
      }
    }
    return(line)
  }, USE.NAMES = FALSE)
  temp_file <- file.path(temp_dir, paste0(label_prefix, "_", basename(template_path)))
  writeLines(processed_lines, temp_file)
  return(temp_file)
}

message(sprintf("Processing %d wavelengths: %s",
                length(wavelengths), paste(wavelengths, collapse = ", ")))
```

# `r tr("multi_overview", lang)`

`r tr("multi_overview_desc", lang, length(wavelengths), paste(wavelengths, collapse = ", "))`

`r tr("multi_compare", lang)`

- `r tr("multi_benefit1", lang)`
- `r tr("multi_benefit2", lang)`
- `r tr("multi_benefit3", lang)`

**`r tr("multi_sections", lang)`**

- `r tr("multi_exec_summary", lang)`
- `r tr("multi_detailed", lang)`

---

```{r generate-wavelength-reports, results='asis'}
for (i in seq_along(wavelengths)) {
  wl <- wavelengths[i]

  # Page break before each wavelength (works in PDF and DOCX)
  cat("\n\n\\newpage\n\n")

  cat(sprintf("\n\n# %s\n\n", tr("wavelength_analysis", lang, wl)))
  cat(sprintf("**%s**\n\n", tr("analysis_n_of", lang, i, length(wavelengths))))

  csv_file <- file.path(output_dir, paste0("long_data_output_", wl, ".csv"))
  if (!file.exists(csv_file)) {
    cat(sprintf("**Error:** Data file not found for %s\n\n", wl))
    next
  }

  wl_output_dir <- file.path(output_dir, wl)
  if (!dir.exists(wl_output_dir)) dir.create(wl_output_dir, recursive = TRUE, showWarnings = FALSE)

  file.copy(from = csv_file, to = file.path(wl_output_dir, "long_data_output.csv"), overwrite = TRUE)

  config_files <- c("assay_config.json", "qc_params.json", "notes.json",
                    "sample_processing_config.json", "tissue_weights.json", "excluded_wells.json",
                    "analysis_config.json")
  for (cfg_file in config_files) {
    src <- file.path(output_dir, cfg_file)
    if (file.exists(src)) file.copy(src, file.path(wl_output_dir, cfg_file), overwrite = TRUE)
  }

  tryCatch({
    template_path <- file.path(script_dir, "unified_analysis_template.Rmd")
    if (!file.exists(template_path)) {
      cat(sprintf("**Error:** Template not found at `%s`\n\n", template_path))
    } else {
      label_prefix <- paste0("wl", gsub("[^a-zA-Z0-9]", "", wl))
      preprocessed_template <- preprocess_template_chunks(template_path, label_prefix)
      wl_env <- new.env(parent = environment())
      wl_env$params <- list(output_dir = wl_output_dir, lang = lang)
      result <- knitr::knit_child(preprocessed_template, envir = wl_env, quiet = TRUE)
      cat(result, sep = "\n")
      unlink(preprocessed_template)
    }
  }, error = function(e) {
    cat(sprintf("**Error rendering %s analysis:**\n\nError: %s\n\n", wl, e$message))
  })

  cat("\n\n---\n\n")
}
```

\newpage

# `r tr("overall_conclusions", lang)`

## `r tr("exec_summary_title", lang)`

```{r wavelength-summary, results='asis'}
tryCatch({

summary_data <- list()

for (wl in wavelengths) {
  csv_file <- file.path(output_dir, paste0("long_data_output_", wl, ".csv"))
  wl_output_dir <- file.path(output_dir, wl)
  stats_file <- file.path(wl_output_dir, "model_stats.json")
  summary_file <- file.path(wl_output_dir, "unknown_results_summary.csv")

  wl_info <- list(wavelength = wl, n_standards = 0L, n_samples = 0L,
                  n_quantified = 0L, r_squared = NA_real_, rmse = NA_real_,
                  ic50 = NA_real_, mean_cv = NA_real_)

  if (file.exists(csv_file)) {
    data_long <- read.csv(csv_file, stringsAsFactors = FALSE)
    wl_info$n_standards <- sum(data_long$SampleType == "Standard", na.rm = TRUE)
    wl_info$n_samples <- sum(data_long$SampleType == "Sample", na.rm = TRUE)

    if (file.exists(stats_file)) {
      stats <- tryCatch(jsonlite::fromJSON(stats_file), error = function(e) NULL)
      if (!is.null(stats)) {
        safe_num <- function(x) tryCatch(as.numeric(x[[1]]), error = function(e) NA_real_, warning = function(w) NA_real_)
        wl_info$r_squared <- safe_num(stats$r_squared)
        wl_info$rmse      <- safe_num(stats$rmse)
        wl_info$ic50      <- safe_num(stats$ic50)
        wl_info$mean_cv   <- safe_num(stats$mean_sample_cv)
      }
    }

    if (file.exists(summary_file)) {
      results <- tryCatch(read.csv(summary_file, stringsAsFactors = FALSE), error = function(e) data.frame())
      wl_info$n_quantified <- nrow(results)
    }
  }

  summary_data[[wl]] <- wl_info
}

if (length(summary_data) > 0) {
  fmt_num <- function(val, digits) {
    if (is.null(val) || length(val) == 0 || !is.numeric(val) || is.na(val) || !is.finite(val)) return("\u2014")
    format(round(val, digits), nsmall = digits)
  }

  summary_df <- data.frame(
    Wavelength = sapply(summary_data, function(x) x$wavelength),
    R2 = sapply(summary_data, function(x) fmt_num(x$r_squared, 4)),
    RMSE = sapply(summary_data, function(x) fmt_num(x$rmse, 3)),
    IC50 = sapply(summary_data, function(x) {
      v <- x$ic50
      if (is.null(v) || !is.numeric(v) || is.na(v) || !is.finite(v)) "\u2014"
      else format(round(v, 1), nsmall = 1, big.mark = ",")
    }),
    Standards = sapply(summary_data, function(x) x$n_standards),
    Samples = sapply(summary_data, function(x) x$n_samples),
    Quantified = sapply(summary_data, function(x) x$n_quantified),
    Mean_CV = sapply(summary_data, function(x) {
      v <- x$mean_cv
      if (is.null(v) || !is.numeric(v) || is.na(v) || !is.finite(v)) "\u2014"
      else paste0(format(round(v, 1), nsmall = 1), "%")
    }),
    stringsAsFactors = FALSE
  )

  names(summary_df) <- c(
    tr("col_wavelength", lang), tr("col_r2", lang), tr("col_rmse", lang),
    tr("col_ic50", lang), tr("col_standards", lang), tr("col_samples", lang),
    tr("col_quantified", lang), tr("col_mean_cv", lang)
  )

  # Use format appropriate for output type
  out_fmt <- knitr::opts_knit$get("rmarkdown.pandoc.to")
  if (!is.null(out_fmt) && out_fmt %in% c("docx", "latex")) {
    print(kable(summary_df, caption = tr("data_overview", lang), format = "pandoc"))
  } else {
    print(kable(summary_df, caption = tr("data_overview", lang)) %>%
      kableExtra::kable_styling(full_width = FALSE, position = "center"))
  }

  rmse_vals <- sapply(summary_data, function(x) {
    v <- x$rmse
    if (is.null(v) || !is.numeric(v) || is.na(v) || !is.finite(v)) NA_real_ else v
  })
  rmse_valid <- rmse_vals[!is.na(rmse_vals)]

  if (length(rmse_valid) > 0) {
    best_wl <- names(which.min(rmse_valid))
    best_rmse <- min(rmse_valid)
    cat("\n\n")
    cat(tr("recommended_wavelength", lang, best_wl, best_rmse))
    cat("\n\n")
  }
}

}, error = function(e) {
  cat(sprintf("\n\n**Executive summary could not be generated:** %s\n\n", e$message))
})
```

## `r tr("concordance_title", lang)`

```{r concordance-analysis, results='asis', fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
tryCatch({
  if (length(wavelengths) >= 2) {
    cat(tr("concordance_desc", lang), "\n\n")

    # Load sample results from each wavelength
    wl_results <- list()
    for (wl in wavelengths) {
      wl_output_dir <- file.path(output_dir, wl)
      summary_file <- file.path(wl_output_dir, "unknown_results_summary.csv")
      if (file.exists(summary_file)) {
        res <- tryCatch(read.csv(summary_file, stringsAsFactors = FALSE), error = function(e) NULL)
        if (!is.null(res) && nrow(res) > 0 && "mean_concentration" %in% names(res)) {
          wl_results[[wl]] <- res
        }
      }
    }

    if (length(wl_results) >= 2) {
      # Lin's CCC function (no external package dependency)
      lins_ccc <- function(x, y) {
        n <- length(x)
        if (n < 3) return(list(ccc = NA_real_, ci_lower = NA_real_, ci_upper = NA_real_))
        mx <- mean(x); my <- mean(y)
        sx <- sd(x); sy <- sd(y)
        sxy <- sum((x - mx) * (y - my)) / (n - 1)
        ccc <- (2 * sxy) / (sx^2 + sy^2 + (mx - my)^2)
        # Fisher Z transform for CI
        z <- 0.5 * log((1 + ccc) / (1 - ccc))
        se_z <- sqrt(1 / (n - 3))
        z_lower <- z - 1.96 * se_z
        z_upper <- z + 1.96 * se_z
        ci_lower <- (exp(2 * z_lower) - 1) / (exp(2 * z_lower) + 1)
        ci_upper <- (exp(2 * z_upper) - 1) / (exp(2 * z_upper) + 1)
        list(ccc = ccc, ci_lower = ci_lower, ci_upper = ci_upper)
      }

      wl_names <- names(wl_results)
      pairs <- combn(wl_names, 2, simplify = FALSE)

      concordance_results <- list()

      for (pair in pairs) {
        wl1 <- pair[1]; wl2 <- pair[2]
        res1 <- wl_results[[wl1]]
        res2 <- wl_results[[wl2]]

        # Match by replicate group
        merge_key <- if ("replicate_group" %in% names(res1)) "replicate_group" else "sample_ids"
        if (!(merge_key %in% names(res1)) || !(merge_key %in% names(res2))) next

        paired <- merge(
          res1 %>% dplyr::select(all_of(merge_key), mean_concentration),
          res2 %>% dplyr::select(all_of(merge_key), mean_concentration),
          by = merge_key, suffixes = c("_1", "_2")
        )
        paired <- paired %>%
          dplyr::filter(!is.na(mean_concentration_1) & !is.na(mean_concentration_2) &
                        is.finite(mean_concentration_1) & is.finite(mean_concentration_2))

        if (nrow(paired) >= 3) {
          x <- as.numeric(paired$mean_concentration_1)
          y <- as.numeric(paired$mean_concentration_2)

          ccc_result <- lins_ccc(x, y)

          # Bland-Altman
          ba_mean <- (x + y) / 2
          ba_diff <- x - y
          bias <- mean(ba_diff)
          loa_lower <- bias - 1.96 * sd(ba_diff)
          loa_upper <- bias + 1.96 * sd(ba_diff)

          concordance_results[[paste(wl1, "vs", wl2)]] <- list(
            wl1 = wl1, wl2 = wl2,
            n = nrow(paired),
            ccc = ccc_result$ccc, ci_lower = ccc_result$ci_lower, ci_upper = ccc_result$ci_upper,
            bias = bias, loa_lower = loa_lower, loa_upper = loa_upper,
            paired = paired, ba_mean = ba_mean, ba_diff = ba_diff
          )
        }
      }

      if (length(concordance_results) > 0) {
        # Summary table
        conc_table <- data.frame(
          Comparison = names(concordance_results),
          n = sapply(concordance_results, function(x) x$n),
          CCC = sapply(concordance_results, function(x) sprintf("%.4f", x$ccc)),
          CI_95 = sapply(concordance_results, function(x) sprintf("[%.4f, %.4f]", x$ci_lower, x$ci_upper)),
          Bias = sapply(concordance_results, function(x) format(x$bias, digits = 4)),
          LoA = sapply(concordance_results, function(x) sprintf("[%.4f, %.4f]", x$loa_lower, x$loa_upper)),
          Agreement = sapply(concordance_results, function(x) {
            if (is.na(x$ccc)) "\u2014"
            else if (x$ccc > 0.99) tr("concordance_excellent", lang)
            else if (x$ccc > 0.95) tr("concordance_good", lang)
            else if (x$ccc > 0.90) tr("concordance_moderate", lang)
            else tr("concordance_poor", lang)
          }),
          stringsAsFactors = FALSE, row.names = NULL
        )
        names(conc_table) <- c("Comparison", "n", tr("concordance_ccc", lang), "95% CI", "Bias", "Limits of Agreement", "Agreement")

        out_fmt <- knitr::opts_knit$get("rmarkdown.pandoc.to")
        if (!is.null(out_fmt) && out_fmt %in% c("docx", "latex")) {
          print(kable(conc_table, caption = tr("concordance_title", lang), format = "pandoc", row.names = FALSE))
        } else {
          print(kable(conc_table, caption = tr("concordance_title", lang), row.names = FALSE) %>%
            kableExtra::kable_styling(full_width = FALSE, position = "center"))
        }

        # Bland-Altman plots for each pair
        cat(sprintf("\n\n### %s\n\n", tr("concordance_bland_altman", lang)))

        for (cr_name in names(concordance_results)) {
          cr <- concordance_results[[cr_name]]
          ba_df <- data.frame(mean_val = cr$ba_mean, diff_val = cr$ba_diff)

          ba_plot <- ggplot2::ggplot(ba_df, ggplot2::aes(x = mean_val, y = diff_val)) +
            ggplot2::geom_point(size = 3, alpha = 0.7, color = "#0072B2") +
            ggplot2::geom_hline(yintercept = cr$bias, linetype = "dashed", color = "black") +
            ggplot2::geom_hline(yintercept = cr$loa_lower, linetype = "dotted", color = "red") +
            ggplot2::geom_hline(yintercept = cr$loa_upper, linetype = "dotted", color = "red") +
            ggplot2::annotate("text", x = max(ba_df$mean_val), y = cr$bias,
                              label = sprintf("Bias = %.3f", cr$bias), hjust = 1, vjust = -0.5) +
            ggplot2::annotate("text", x = max(ba_df$mean_val), y = cr$loa_upper,
                              label = sprintf("+1.96 SD = %.3f", cr$loa_upper), hjust = 1, vjust = -0.5, color = "red") +
            ggplot2::annotate("text", x = max(ba_df$mean_val), y = cr$loa_lower,
                              label = sprintf("-1.96 SD = %.3f", cr$loa_lower), hjust = 1, vjust = 1.5, color = "red") +
            ggplot2::labs(
              title = sprintf("Bland-Altman: %s", cr_name),
              x = sprintf("Mean of %s and %s", cr$wl1, cr$wl2),
              y = sprintf("Difference (%s - %s)", cr$wl1, cr$wl2)
            ) +
            ggplot2::theme_classic()

          print(ba_plot)
          cat("\n\n")
        }
      } else {
        cat(tr("concordance_no_data", lang), "\n\n")
      }
    } else {
      cat(tr("concordance_no_data", lang), "\n\n")
    }
  }
}, error = function(e) {
  cat(sprintf("\n\n*Concordance analysis failed: %s*\n\n", e$message))
})
```

```{r final-comparison, results='asis'}
cat(sprintf("## %s\n\n", tr("wavelength_performance", lang)))
cat(sprintf("**%s**\n\n", tr("recommendations", lang)))
cat(sprintf("- %s\n", tr("rec_r2", lang)))
cat(sprintf("- %s\n", tr("rec_cv", lang)))
cat(sprintf("- %s\n\n", tr("rec_separation", lang)))
```

---

**`r tr("report_generated", lang)`** `r Sys.Date()`
**`r tr("contact", lang)`** kr.moeller@iaea.org
**`r tr("feedback", lang)`** [`r tr("online_form", lang)`](https://forms.office.com/e/q8eqJfp4QM)

*`r tr("automated_multi", lang)`*
